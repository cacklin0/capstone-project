{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal - MLND Capstone Project\n",
    "### Chad Acklin\n",
    "***\n",
    "\n",
    "\n",
    "## Data Acquisition\n",
    "As noted in the project proposal, due to the privacy concerns of real-world personally identifiable datasets, this project will make use of synthetically generated data.  The initial dataset was generated with the generate tool published by the [Freely Extensible Biomedical Record Linkage](http://users.cecs.anu.edu.au/~Peter.Christen/Febrl/febrl-0.3/febrldoc-0.3/node70.html) package.  The FEBRL tool generates a dataset of demographic data and introduces noise that mimics OCR errors, typograhic errors, and phonetic misspellings.  \n",
    "\n",
    "A dataset of 30,000 originals and 15,000 matches was generated, stored as a csv, and loaded below.  Originals have an id of rec-X-org and matches have an id of rec-X-dup-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>dob</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec_id</td>\n",
       "      <td>culture</td>\n",
       "      <td>sex</td>\n",
       "      <td>age</td>\n",
       "      <td>date_of_birth</td>\n",
       "      <td>title</td>\n",
       "      <td>given_name</td>\n",
       "      <td>surname</td>\n",
       "      <td>state</td>\n",
       "      <td>suburb</td>\n",
       "      <td>postcode</td>\n",
       "      <td>street_number</td>\n",
       "      <td>address_1</td>\n",
       "      <td>address_2</td>\n",
       "      <td>phone_number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-0-dup-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>28</td>\n",
       "      <td>19901218</td>\n",
       "      <td></td>\n",
       "      <td>caitlin</td>\n",
       "      <td>chappel</td>\n",
       "      <td></td>\n",
       "      <td>pres</td>\n",
       "      <td>4504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g'lbbes street</td>\n",
       "      <td></td>\n",
       "      <td>087631 3909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec-0-dup-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>19901218</td>\n",
       "      <td></td>\n",
       "      <td>cait in</td>\n",
       "      <td>chap pl</td>\n",
       "      <td></td>\n",
       "      <td>preston</td>\n",
       "      <td>4504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gibbess  reet</td>\n",
       "      <td></td>\n",
       "      <td>087631 909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>28</td>\n",
       "      <td>19901218</td>\n",
       "      <td></td>\n",
       "      <td>caitlin</td>\n",
       "      <td>chappel</td>\n",
       "      <td></td>\n",
       "      <td>preston</td>\n",
       "      <td>4504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gibbes street</td>\n",
       "      <td></td>\n",
       "      <td>08 76313909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec-1-org</td>\n",
       "      <td>ind</td>\n",
       "      <td>f</td>\n",
       "      <td></td>\n",
       "      <td>19630324</td>\n",
       "      <td></td>\n",
       "      <td>oscar</td>\n",
       "      <td>murjani</td>\n",
       "      <td>vic</td>\n",
       "      <td>bright</td>\n",
       "      <td>2060</td>\n",
       "      <td>14</td>\n",
       "      <td>aspinall street</td>\n",
       "      <td></td>\n",
       "      <td>618 53569883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id nationality gender   age             dob   title   first_name  \\\n",
       "0       rec_id     culture    sex   age   date_of_birth   title   given_name   \n",
       "1  rec-0-dup-0         NaN      f    28        19901218              caitlin   \n",
       "2  rec-0-dup-1         NaN      f     2        19901218              cait in   \n",
       "3    rec-0-org         NaN      f    28        19901218              caitlin   \n",
       "4    rec-1-org         ind      f              19630324                oscar   \n",
       "\n",
       "  last_name   state      city        zip  street_number         address_1  \\\n",
       "0   surname   state    suburb   postcode  street_number         address_1   \n",
       "1   chappel            pres         4504            NaN    g'lbbes street   \n",
       "2   chap pl           preston       4504            NaN     gibbess  reet   \n",
       "3   chappel           preston       4504            NaN     gibbes street   \n",
       "4   murjani     vic    bright       2060             14   aspinall street   \n",
       "\n",
       "    address_2          phone  \n",
       "0   address_2   phone_number  \n",
       "1                087631 3909  \n",
       "2                 087631 909  \n",
       "3                08 76313909  \n",
       "4               618 53569883  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['id', 'nationality', 'gender', 'age', 'dob', 'title',\n",
    "       'first_name', 'last_name', 'state', 'city', 'zip',\n",
    "       'street_number', 'address_1', 'address_2', 'phone']\n",
    "df = pd.read_csv('FEBRL_sample_data.csv', encoding = 'latin1', names = col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After loading the dataset, several additional features are calculated including phonetic representations of first name, last name, and city.  These were created using the metaphone algorithm available in the jellyfish package\n",
    "\n",
    "Data is into 2 dataframes by originals and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Recordset: (30000, 23)\n",
      "Recordset of matches: (15000, 23)\n"
     ]
    }
   ],
   "source": [
    "df[['prefix','trueRecordID', 'OrgDup', 'seqNum']] = df.id.str.split('-', expand=True)\n",
    "df.drop('prefix', axis=1, inplace=True)\n",
    "df.fillna ('', inplace=True)\n",
    "df['last_name_met'] = df['last_name'].str.replace(' ', '').apply(lambda x: jellyfish.metaphone(x))\n",
    "df['first_name_met'] = df['first_name'].str.replace(' ', '').apply(lambda x: jellyfish.metaphone(x))\n",
    "df['city_met'] = df['city'].str.replace(' ', '').apply(lambda x: jellyfish.metaphone(x))\n",
    "df['phone'] = df['phone'].str.replace(' ', '')\n",
    "df['predicateLastName'] = df['last_name'].str[:2]\n",
    "df['predicateFirstName'] = df['first_name'].str[:2]\n",
    "\n",
    "\n",
    "dfDup = df[df.OrgDup == 'dup']\n",
    "dfOrg = df[df.OrgDup == 'org']\n",
    "dfDup.columns = [str(col) + '_match' for col in dfDup.columns]\n",
    "dfOrg.columns = [str(col) + '_org' for col in dfOrg.columns]\n",
    "print('Original Recordset:', dfOrg.shape)\n",
    "print('Recordset of matches:', dfDup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking\n",
    "\n",
    "The demographics are uses to \"block\" potential mathes between the datasets.  Some trial and error was used here to find a balance of limiting the dataset and the completeness of including all matching pairs.  If every original were compared to every potential match, the resultant dataset would be 450M rows (30,000 x 15,000).  Blocking limits the number of comparisons that will be required.\n",
    "\n",
    "After blocking, the paired dataset includes slightly more than 4.18M rows and has only failed to include 11 matches.  This is an acceptable trade-off for this task and the blocked matches becomes the basis for building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfZipMatches = pd.merge(dfOrg, dfDup, how='inner', left_on='zip_org', right_on='zip_match')\n",
    "dfSurnameMatches = pd.merge(dfOrg, dfDup, how='inner', left_on='last_name_met_org', right_on='last_name_met_match')\n",
    "#dfFirstMatches = pd.merge(dfOrg, dfDup, how='inner', left_on='first_name_met_org', right_on='first_name_met_match')\n",
    "#dfFirstLastMatch = pd.merge(dfOrg, dfDup, how='inner', left_on='last_name_met_org', right_on='first_name_met_match')\n",
    "dfCityMatches = pd.merge(dfOrg, dfDup, how='inner', left_on='city_met_org', right_on='city_met_match')\n",
    "#dfStateMatches = pd.merge(dfOrg, dfDup, how='left', left_on='state_org', right_on='zip_match')\n",
    "dfPhoneMatches = pd.merge(dfOrg, dfDup, how='inner', left_on='phone_org', right_on='phone_match')\n",
    "dfPredicateMatches = pd.merge(dfOrg, dfDup, how='inner'\n",
    "                                , left_on=['predicateFirstName_org', 'predicateLastName_org']\n",
    "                                , right_on=['predicateFirstName_match', 'predicateLastName_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421896, 46)\n",
      "(689347, 46)\n",
      "(174402, 46)\n",
      "(1196104, 46)\n",
      "(1785915, 46)\n"
     ]
    }
   ],
   "source": [
    "matchFrames = [ dfZipMatches\n",
    "              , dfSurnameMatches\n",
    "              #, dfFirstMatches \n",
    "              #, dfFirstLastMatch\n",
    "              , dfCityMatches\n",
    "              #, dfStateMatches\n",
    "              , dfPhoneMatches\n",
    "              , dfPredicateMatches\n",
    "              ]\n",
    "\n",
    "for m in matchFrames:\n",
    "    print( m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfBlockedMatches = pd.concat(matchFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183821, 46)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean up a little and drop duplicates\n",
    "\n",
    "dfBlockedMatches.fillna('0', inplace=True)\n",
    "dfBlockedMatches.drop_duplicates(subset=['id_org', 'id_match'], inplace=True)\n",
    "dfBlockedMatches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfBlockedMatches['MATCH'] = np.where(dfBlockedMatches[\n",
    "        'trueRecordID_org']==dfBlockedMatches['trueRecordID_match'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14989"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many of the 15,000 matches have we included in the dataset?\n",
    "sum(dfBlockedMatches.MATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Next, features are engineered that compare the edit distance of associated strings between the original and match.  This step uses the Damerau Levenshtein edit distance to determine the similarity of the strings.  Then, the edit distances are scaled by a factor of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfBlockedMatches['phone_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['phone_org'], x['phone_match']), axis=1)\n",
    "dfBlockedMatches['last_name_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['last_name_org'], x['last_name_match']), axis=1)\n",
    "dfBlockedMatches['first_name_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['first_name_org'], x['first_name_match']), axis=1)\n",
    "dfBlockedMatches['city_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['city_org'], x['city_match']), axis=1)\n",
    "dfBlockedMatches['state_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['state_org'], x['state_match']), axis=1)\n",
    "dfBlockedMatches['address_1_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['address_1_org'], x['address_1_match']), axis=1)\n",
    "dfBlockedMatches['address_1_2_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['address_1_org'], x['address_2_match']), axis=1)\n",
    "dfBlockedMatches['dob_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['dob_org'], x['dob_match']), axis=1)\n",
    "dfBlockedMatches['zip_dlev'] = dfBlockedMatches.apply(lambda x: jellyfish.damerau_levenshtein_distance\n",
    "                                                        (x['zip_org'], x['zip_match']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_invert(x):\n",
    "    scaled = 1-(x/10)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfBlockedMatches['phone_scaled'] = dfBlockedMatches['phone_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['last_name_scaled'] = dfBlockedMatches['last_name_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['first_name_scaled'] = dfBlockedMatches['first_name_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['city_scaled'] = dfBlockedMatches['city_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['state_scaled'] = dfBlockedMatches['state_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['address_1_scaled'] = dfBlockedMatches['address_1_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['address_1_2_scaled'] = dfBlockedMatches['address_1_2_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['dob_scaled'] = dfBlockedMatches['dob_dlev'].apply(scale_invert)\n",
    "dfBlockedMatches['zip_scaled'] = dfBlockedMatches['zip_dlev'].apply(scale_invert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset\n",
    "\n",
    "The final dataset is saved as csv and a sample generated to attach to the proposal.  The final dataset includes the original id, the id from the matching dataset, a \"MATCH\" indicator that will be our target variable, and scaled features based upon the string edit distances calculated above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatures = dfBlockedMatches[[ 'id_org', 'id_match', 'MATCH',\n",
    "       'phone_scaled', 'last_name_scaled', 'first_name_scaled', 'city_scaled',\n",
    "       'state_scaled', 'address_1_scaled', 'address_1_2_scaled', 'dob_scaled',\n",
    "       'zip_scaled']]\n",
    "dfFeatures.to_csv('dfFeatures.csv')\n",
    "dfFeatures.sample(n=100000).to_csv('dfFeatures_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_org</th>\n",
       "      <th>id_match</th>\n",
       "      <th>MATCH</th>\n",
       "      <th>phone_scaled</th>\n",
       "      <th>last_name_scaled</th>\n",
       "      <th>first_name_scaled</th>\n",
       "      <th>city_scaled</th>\n",
       "      <th>state_scaled</th>\n",
       "      <th>address_1_scaled</th>\n",
       "      <th>address_1_2_scaled</th>\n",
       "      <th>dob_scaled</th>\n",
       "      <th>zip_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>rec-0-dup-0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>rec-0-dup-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>rec-11006-dup-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>rec-11006-dup-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec-0-org</td>\n",
       "      <td>rec-12494-dup-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_org         id_match  MATCH  phone_scaled  last_name_scaled  \\\n",
       "0  rec-0-org      rec-0-dup-0      1           1.0               1.0   \n",
       "1  rec-0-org      rec-0-dup-1      1           0.9               0.8   \n",
       "2  rec-0-org  rec-11006-dup-0      0           0.2               0.3   \n",
       "3  rec-0-org  rec-11006-dup-1      0           0.2               0.3   \n",
       "4  rec-0-org  rec-12494-dup-1      0           0.1               0.3   \n",
       "\n",
       "   first_name_scaled  city_scaled  state_scaled  address_1_scaled  \\\n",
       "0                1.0          0.7           1.0               0.8   \n",
       "1                0.9          1.0           1.0               0.8   \n",
       "2                0.4          0.0           1.0              -0.1   \n",
       "3                0.4          0.0           1.0               0.0   \n",
       "4                0.4          0.2           0.9               0.5   \n",
       "\n",
       "   address_1_2_scaled  dob_scaled  zip_scaled  \n",
       "0                -0.3         1.0         1.0  \n",
       "1                -0.3         1.0         1.0  \n",
       "2                 0.0         0.5         1.0  \n",
       "3                -0.1         0.5         1.0  \n",
       "4                -0.3         0.6         1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183821, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
